# ğŸ¤– OllamaBot

<div align="center">

![OllamaBot Banner](https://img.shields.io/badge/OllamaBot-Local_AI_IDE-7dcfff?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9IiM3ZGNmZmYiIHN0cm9rZS13aWR0aD0iMiIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIiBzdHJva2UtbGluZWpvaW49InJvdW5kIj48cGF0aCBkPSJNMTggOGE2IDYgMCAwIDAtMTIgMGMwIDcgMTIgNyAxMiAwWiIvPjxjaXJjbGUgY3g9IjEyIiBjeT0iOCIgcj0iNiIvPjwvc3ZnPg==)

**A native macOS IDE with Infinite Mode â€” autonomous AI agents powered by local Ollama models**

[![macOS](https://img.shields.io/badge/macOS-14.0+-000000?style=flat-square&logo=apple&logoColor=white)](https://www.apple.com/macos/)
[![Swift](https://img.shields.io/badge/Swift-5.9+-F05138?style=flat-square&logo=swift&logoColor=white)](https://swift.org)
[![Ollama](https://img.shields.io/badge/Ollama-Local_AI-white?style=flat-square)](https://ollama.ai)
[![License](https://img.shields.io/badge/License-MIT-9ece6a?style=flat-square)](LICENSE)

[Features](#-features) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Architecture](#-architecture) â€¢ [Configuration](#-configuration)

</div>

---

## âœ¨ What Makes OllamaBot Different

Traditional AI coding tools wait for your commands. **OllamaBot's Infinite Mode** flips this paradigm:

- ğŸ”„ **Autonomous Operation** â€” Give it a task, watch it work until completion
- ğŸ§  **Multi-Model Orchestration** â€” 4 specialized AI models working in coordination  
- ğŸ’» **100% Local** â€” No API costs, no usage limits, complete privacy
- âš¡ **Apple Silicon Optimized** â€” Built for M1/M2/M3 performance

---

## ğŸ­ The Model Orchestra

OllamaBot coordinates four specialized 32B parameter models, each excelling at different tasks:

| Model | Role | Color | Specialization |
|-------|------|-------|----------------|
| **Qwen3 32B** | ğŸ§  Orchestrator | ![#bb9af7](https://via.placeholder.com/12/bb9af7/bb9af7.png) Purple | Thinking, planning, delegating tasks |
| **Command-R 35B** | ğŸ” Researcher | ![#7aa2f7](https://via.placeholder.com/12/7aa2f7/7aa2f7.png) Blue | Research, RAG, documentation |
| **Qwen2.5-Coder 32B** | ğŸ’» Coder | ![#ff9e64](https://via.placeholder.com/12/ff9e64/ff9e64.png) Orange | Code generation, debugging, refactoring |
| **Qwen3-VL 32B** | ğŸ‘ï¸ Vision | ![#9ece6a](https://via.placeholder.com/12/9ece6a/9ece6a.png) Green | Image analysis, UI inspection |

---

## ğŸš€ Features

### ğŸ”® Infinite Mode (The Star Feature)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     YOU GIVE A TASK                         â”‚
â”‚           "Add user authentication to this app"             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              QWEN3 (ORCHESTRATOR) - The Brain               â”‚
â”‚                                                             â”‚
â”‚   Uses tools: think, read_file, search_files, list_dir,    â”‚
â”‚   delegate_to_coder, delegate_to_researcher, etc.          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“                    â†“                    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ COMMAND-R    â”‚   â”‚ QWEN-CODER   â”‚   â”‚ QWEN3-VL     â”‚
    â”‚ (Research)   â”‚   â”‚ (Coding)     â”‚   â”‚ (Vision)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
              [Results fed back to Orchestrator]
                              â†“
                [Loop continues until complete]
```

**13 Built-in Agent Tools:**

| Tool | Description |
|------|-------------|
| `think` | Plan and reason about the task |
| `read_file` | Read file contents |
| `write_file` | Create or overwrite files |
| `edit_file` | Search and replace in files |
| `search_files` | Search text across the codebase |
| `list_directory` | Explore directory structure |
| `run_command` | Execute shell commands |
| `ask_user` | Request user input |
| `delegate_to_coder` | Send coding tasks to Qwen-Coder |
| `delegate_to_researcher` | Send research tasks to Command-R |
| `delegate_to_vision` | Send image analysis to Qwen-VL |
| `take_screenshot` | Capture screen for vision analysis |
| `complete` | Signal task completion |

### ğŸ’¬ Chat Mode

- Quick conversations with any model
- **Auto-routing** based on question type
- Manual model override with keyboard shortcuts
- Context-aware â€” includes open files and selections
- `@filename` mentions for additional context

### ğŸ–¥ï¸ Full IDE

- **File Explorer** with syntax-colored icons
- **Code Editor** with line numbers, syntax highlighting
- **Integrated Terminal** with PTY support
- **Multiple Tabs** with modification indicators
- **Breadcrumb Navigation**
- **Status Bar** with model/connection info
- **Command Palette** (`âŒ˜â‡§P`)
- **Quick Open** (`âŒ˜P`)
- **Global Search** (`âŒ˜â‡§F`)
- **Find & Replace** (`âŒ˜F` / `âŒ˜âŒ¥F`)
- **Go to Line** (`âŒƒG`)

### âš¡ Performance Optimized

| Layer | Optimization |
|-------|-------------|
| **File I/O** | Memory-mapped for files >64KB |
| **Caching** | LRU with `os_unfair_lock` |
| **Search** | Parallel trigram + word indexing |
| **Ollama** | Task-specific temperature/tokens |
| **Memory** | Auto-clear under pressure |
| **Models** | Pre-warmed on launch |

---

## ğŸ“¦ Installation

### Prerequisites

- **macOS 14.0** (Sonoma) or later
- **Apple Silicon** Mac (M1/M2/M3)
- **32GB RAM** minimum (for 32B models)
- **Ollama** installed

### Step 1: Install Ollama

```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### Step 2: Pull the Models

```bash
# Orchestrator (required)
ollama pull qwen3:32b

# Research Model
ollama pull command-r:35b

# Coding Model
ollama pull qwen2.5-coder:32b

# Vision Model (optional)
ollama pull qwen3-vl:32b
```

### Step 3: Clone & Build

```bash
git clone https://github.com/cadenroberts/ollamabot.git
cd ollamabot

# Generate app icon (requires ImageMagick: brew install imagemagick)
./scripts/generate-icon.sh

# Build the app bundle
./scripts/build-app.sh --release
```

### Step 4: Install & Run

```bash
# Install to Applications
cp -r build/OllamaBot.app /Applications/

# Or run directly
open build/OllamaBot.app
```

Or for development:
```bash
swift run OllamaBot
```

Or open in Xcode:
```bash
open Package.swift
```

---

## ğŸ¯ Usage

### Infinite Mode

1. Press `âŒ˜â‡§I` or click the **âˆ** button
2. Describe your task:
   - *"Add dark mode support to all views"*
   - *"Refactor this codebase to use async/await"*
   - *"Create unit tests for the user service"*
   - *"Document all public functions"*
3. Click **Start** and watch it work
4. **Stop** anytime to take control

### Chat Mode

Type in the chat panel on the right. The model auto-selects based on your question, or force a specific model:

| Shortcut | Model |
|----------|-------|
| `âŒ˜â‡§1` | Qwen3 (Writing) |
| `âŒ˜â‡§2` | Command-R (Research) |
| `âŒ˜â‡§3` | Qwen-Coder (Coding) |
| `âŒ˜â‡§4` | Qwen-VL (Vision) |
| `âŒ˜â‡§0` | Auto-route |

### Keyboard Shortcuts

| Shortcut | Action |
|----------|--------|
| `âŒ˜O` | Open folder |
| `âŒ˜N` | New file |
| `âŒ˜S` | Save file |
| `âŒ˜P` | Quick open |
| `âŒ˜â‡§P` | Command palette |
| `âŒ˜F` | Find in file |
| `âŒ˜â‡§F` | Search in files |
| `âŒ˜âŒ¥F` | Find and replace |
| `âŒƒG` | Go to line |
| `âŒ˜B` | Toggle sidebar |
| `âŒƒ\`` | Toggle terminal |
| `âŒ˜â‡§I` | Toggle Infinite Mode |

---

## ğŸ—ï¸ Architecture

```
OllamaBot/
â”œâ”€â”€ Sources/
â”‚   â”œâ”€â”€ OllamaBotApp.swift           # App entry, state management
â”‚   â”œâ”€â”€ Agent/
â”‚   â”‚   â”œâ”€â”€ AgentExecutor.swift      # Infinite Mode engine
â”‚   â”‚   â””â”€â”€ AgentTools.swift         # 13 tool definitions
â”‚   â”œâ”€â”€ Models/
â”‚   â”‚   â”œâ”€â”€ ChatMessage.swift        # Chat data model
â”‚   â”‚   â”œâ”€â”€ FileItem.swift           # File tree model
â”‚   â”‚   â””â”€â”€ OllamaModel.swift        # Model enum + metadata
â”‚   â”œâ”€â”€ Services/
â”‚   â”‚   â”œâ”€â”€ OllamaService.swift      # Ollama API client
â”‚   â”‚   â”œâ”€â”€ IntentRouter.swift       # Model routing logic
â”‚   â”‚   â”œâ”€â”€ ContextBuilder.swift     # Prompt construction
â”‚   â”‚   â”œâ”€â”€ FileIndexer.swift        # Background search index
â”‚   â”‚   â”œâ”€â”€ FileSystemService.swift  # File operations
â”‚   â”‚   â””â”€â”€ ConfigurationService.swift
â”‚   â”œâ”€â”€ Utilities/
â”‚   â”‚   â”œâ”€â”€ DesignSystem.swift       # UI components & tokens
â”‚   â”‚   â”œâ”€â”€ PerformanceCore.swift    # Caches, async I/O
â”‚   â”‚   â”œâ”€â”€ SyntaxHighlighter.swift  # Code highlighting
â”‚   â”‚   â””â”€â”€ Benchmarks.swift         # Performance testing
â”‚   â””â”€â”€ Views/
â”‚       â”œâ”€â”€ MainView.swift           # Main layout
â”‚       â”œâ”€â”€ AgentView.swift          # Infinite Mode UI
â”‚       â”œâ”€â”€ ChatView.swift           # Chat panel
â”‚       â”œâ”€â”€ EditorView.swift         # Code editor
â”‚       â”œâ”€â”€ TerminalView.swift       # Terminal emulator
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ Resources/
â”‚   â”œâ”€â”€ Info.plist                   # App bundle metadata
â”‚   â”œâ”€â”€ AppIcon.icns                 # App icon
â”‚   â””â”€â”€ icon.svg                     # Source icon
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build-app.sh                 # Build .app bundle
â”‚   â””â”€â”€ generate-icon.sh             # Generate .icns from SVG
â”‚
â”œâ”€â”€ Package.swift                    # Swift Package Manager
â”œâ”€â”€ push.sh                          # Git push script
â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration

Access settings via `âŒ˜,` or the menu bar.

### Editor
- Font family & size
- Tab size & spaces
- Word wrap
- Line numbers
- Minimap
- Auto-close brackets
- Format on save

### AI
- Default model
- Temperature (0.0 - 1.0)
- Max tokens
- Context window size
- Include file context
- Stream responses

### Agent (Infinite Mode)
- Max steps limit
- Allow terminal commands
- Allow file writes
- Confirm destructive actions

### Appearance
- Theme (System/Light/Dark)
- Sidebar width
- Status bar visibility
- Breadcrumbs

---

## ğŸ¨ Design System

OllamaBot uses a **Tokyo Night**-inspired color palette:

```swift
// Core Colors
background:     #1a1b26  // Deep background
surface:        #1f2335  // Cards, panels
accent:         #7dcfff  // Brand cyan

// Model Colors  
orchestrator:   #bb9af7  // Purple (Qwen3)
researcher:     #7aa2f7  // Blue (Command-R)
coder:          #ff9e64  // Orange (Qwen-Coder)
vision:         #9ece6a  // Green (Qwen-VL)

// Semantic
success:        #9ece6a
warning:        #e0af68
error:          #f7768e
```

---

## ğŸ”§ Troubleshooting

### "Ollama Disconnected"
```bash
ollama serve
```

### Slow Model Switching
Normal â€” 32B models take ~30s to load. The orchestrator stays warm.

### High Memory Usage
Use **Debug â†’ Clear Caches** or restart the app.

### Agent Seems Stuck
Check the step list â€” it may be thinking or waiting. Stop and retry with a more specific task.

---

## ğŸ“Š Performance

Run benchmarks: **Debug â†’ Run Performance Benchmarks**

Typical results on M1 Max 32GB:

| Metric | Value |
|--------|-------|
| Cache ops | ~400,000/sec |
| File reads (small) | ~35,000/sec |
| File reads (1MB) | ~20/sec (mmap) |
| Parallel speedup | 3.5x |
| First AI response | ~instant (warmed) |

---

## ğŸ¤ Contributing

Contributions welcome! This is an experiment in local AI autonomy.

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run `swift build` to verify
5. Submit a pull request

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai) for making local LLMs accessible
- [SwiftTerm](https://github.com/migueldeicaza/SwiftTerm) for terminal emulation
- [Tokyo Night](https://github.com/enkia/tokyo-night-vscode-theme) for color inspiration

---

<div align="center">

**Built with â¤ï¸ for local AI enthusiasts**

*Your AI should work FOR you, not wait ON you.*

</div>
