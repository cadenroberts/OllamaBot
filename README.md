# ü§ñ OllamaBot

<div align="center">

![OllamaBot Banner](https://img.shields.io/badge/OllamaBot-Local_AI_IDE-7dcfff?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9IiM3ZGNmZmYiIHN0cm9rZS13aWR0aD0iMiIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIiBzdHJva2UtbGluZWpvaW49InJvdW5kIj48cGF0aCBkPSJNMTggOGE2IDYgMCAwIDAtMTIgMGMwIDcgMTIgNyAxMiAwWiIvPjxjaXJjbGUgY3g9IjEyIiBjeT0iOCIgcj0iNiIvPjwvc3ZnPg==)

**A native macOS IDE with Infinite Mode ‚Äî autonomous AI agents powered by local Ollama models**

[![macOS](https://img.shields.io/badge/macOS-14.0+-000000?style=flat-square&logo=apple&logoColor=white)](https://www.apple.com/macos/)
[![Swift](https://img.shields.io/badge/Swift-5.9+-F05138?style=flat-square&logo=swift&logoColor=white)](https://swift.org)
[![Ollama](https://img.shields.io/badge/Ollama-Local_AI-white?style=flat-square)](https://ollama.ai)
[![License](https://img.shields.io/badge/License-MIT-9ece6a?style=flat-square)](LICENSE)

[Features](#-features) ‚Ä¢ [Installation](#-installation) ‚Ä¢ [Usage](#-usage) ‚Ä¢ [Architecture](#-architecture) ‚Ä¢ [Configuration](#-configuration)

</div>

---

## ‚ú® What Makes OllamaBot Different

Traditional AI coding tools wait for your commands. **OllamaBot's AI Modes** flip this paradigm:

- üîÑ **Infinite Mode** ‚Äî Give it a task, watch it work until completion
- ‚ú® **Explore Mode** ‚Äî Continuous autonomous improvement of your project
- üß† **Multi-Model Orchestration** ‚Äî 4 specialized AI models working in coordination  
- üíª **100% Local** ‚Äî No API costs, no usage limits, complete privacy
- ‚ö° **Apple Silicon Optimized** ‚Äî Built for M1/M2/M3 performance
- üõ°Ô∏è **Safely Infinite** ‚Äî Power loss recovery, checkpoints, resilient operation
- üåê **Works Offline** ‚Äî All models run locally, no internet required
- üîí **Privacy First** ‚Äî All telemetry and session data stored locally; no external reporting

---

## üé≠ The Model Orchestra

OllamaBot coordinates four specialized 32B parameter models, each excelling at different tasks:

| Model | Role | Color | Specialization |
|-------|------|-------|----------------|
| **Qwen3 32B** | üß† Orchestrator | ![#7aa2f7](https://via.placeholder.com/12/7aa2f7/7aa2f7.png) Royal Blue | Thinking, planning, delegating tasks |
| **Command-R 35B** | üîç Researcher | ![#2ac3de](https://via.placeholder.com/12/2ac3de/2ac3de.png) Teal Blue | Research, RAG, documentation |
| **Qwen2.5-Coder 32B** | üíª Coder | ![#7dcfff](https://via.placeholder.com/12/7dcfff/7dcfff.png) Cyan Blue | Code generation, debugging, refactoring |
| **Qwen3-VL 32B** | üëÅÔ∏è Vision | ![#5a8fd4](https://via.placeholder.com/12/5a8fd4/5a8fd4.png) Steel Blue | Image analysis, UI inspection |

---

## üöÄ Features

### üîÆ Infinite Mode (The Star Feature)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     YOU GIVE A TASK                         ‚îÇ
‚îÇ           "Add user authentication to this app"             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              QWEN3 (ORCHESTRATOR) - The Brain               ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ   Uses tools: think, read_file, search_files, list_dir,    ‚îÇ
‚îÇ   delegate_to_coder, delegate_to_researcher, etc.          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì                    ‚Üì                    ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ COMMAND-R    ‚îÇ   ‚îÇ QWEN-CODER   ‚îÇ   ‚îÇ QWEN3-VL     ‚îÇ
    ‚îÇ (Research)   ‚îÇ   ‚îÇ (Coding)     ‚îÇ   ‚îÇ (Vision)     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
              [Results fed back to Orchestrator]
                              ‚Üì
                [Loop continues until complete]
```

**18 Built-in Agent Tools:**

| Category | Tool | Description |
|----------|------|-------------|
| **Core** | `think` | Plan and reason about the task |
| | `complete` | Signal task completion |
| | `ask_user` | Request user input |
| **Files** | `read_file` | Read file contents |
| | `write_file` | Create or overwrite files |
| | `edit_file` | Search and replace in files |
| | `search_files` | Search text across the codebase |
| | `list_directory` | Explore directory structure |
| **System** | `run_command` | Execute shell commands |
| | `take_screenshot` | Capture screen for vision analysis |
| **AI Delegation** | `delegate_to_coder` | Send coding tasks to Qwen-Coder |
| | `delegate_to_researcher` | Send research tasks to Command-R |
| | `delegate_to_vision` | Send image analysis to Qwen-VL |
| **Web** | `web_search` | Search the web via DuckDuckGo |
| | `fetch_url` | Fetch and extract web page content |
| **Git** | `git_status` | Get repository status |
| | `git_diff` | View file or repo diffs |
| | `git_commit` | Stage and commit changes |

### ‚ú® Explore Mode (New!)

Where Infinite Mode completes a single task, **Explore Mode** continuously improves your project:

```
Original Goal: "Build a sandwich app"
     ‚îÇ
     ‚ñº  EXPLORE CYCLE
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. UNDERSTANDING - Analyze codebase‚îÇ
‚îÇ  2. EXPANDING - Add new features    ‚îÇ
‚îÇ  3. SPECIFYING - Edge cases, errors ‚îÇ
‚îÇ  4. STANDARDIZING - Apply patterns  ‚îÇ
‚îÇ  5. DOCUMENTING - Auto-update docs  ‚îÇ
‚îÇ  6. REFLECTING - Plan next cycle    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚ñº  REPEAT FOREVER
Basic deli app ‚Üí Ordering system ‚Üí Route optimization ‚Üí ...
```

**Key Features:**
- **Autonomous expansion** ‚Äî keeps adding features aligned with your goal
- **Auto-documentation** ‚Äî generates docs every N changes
- **Configurable style** ‚Äî Conservative, Balanced, or Aggressive exploration
- **Pausable** ‚Äî pause and redirect focus anytime
- **Ground truth** ‚Äî always stays true to your original goal

Configure via `.obotrules`:
```markdown
## Explore Mode Rules
- Maximum expansion depth: 3 levels
- Focus areas: [performance, features, testing]
- Auto-document after: 5 changes
- Expansion style: balanced
```

### üí¨ Chat Mode

- Quick conversations with any model
- **Auto-routing** based on question type
- Manual model override with keyboard shortcuts
- Context-aware ‚Äî includes open files and selections
- `@filename` mentions for additional context
- **Persistent chat history** ‚Äî conversations saved across sessions

### üìä Competitive Benchmark

| Feature | Cursor | Windsurf | VS Code | **OllamaBot** |
|---------|:------:|:--------:|:-------:|:-------------:|
| Inline Tab Completions | ‚úÖ | ‚úÖ | ‚úÖ (Copilot) | ‚úÖ |
| Chat with AI | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| Agentic Mode | ‚úÖ | ‚úÖ (Cascade) | ‚ùå | ‚úÖ (Infinite) |
| **Multi-Model Orchestration** | ‚ùå | ‚ùå | ‚ùå | **‚úÖ** |
| @ Mentions | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| Diff View | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| Git Integration | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| Web Search | ‚úÖ | ‚úÖ | ‚ùå | ‚úÖ |
| Chat History | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| Symbol Outline | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| Problems Panel | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| **100% Local/Private** | ‚ùå | ‚ùå | ‚ùå | **‚úÖ** |
| **No API Costs** | ‚ùå | ‚ùå | ‚ùå | **‚úÖ** |
| Native macOS | ‚ùå | ‚ùå | ‚ùå | **‚úÖ** |

### üñ•Ô∏è Full IDE

- **File Explorer** with syntax-colored icons
- **Code Editor** with line numbers, syntax highlighting
- **Integrated Terminal** with PTY support
- **Multiple Tabs** with modification indicators
- **Breadcrumb Navigation**
- **Status Bar** with model/connection info
- **Command Palette** (`‚åò‚áßP`)
- **Quick Open** (`‚åòP`)
- **Global Search** (`‚åò‚áßF`)
- **Find & Replace** (`‚åòF` / `‚åò‚å•F`)
- **Go to Line** (`‚åÉG`)

### üñ•Ô∏è System Integration

- **RAM Monitoring** ‚Äî Real-time memory tracking with Activity Monitor-like interface
- **Process Manager** ‚Äî Force quit memory-hungry apps directly from OllamaBot
- **Network Aware** ‚Äî Detects WiFi/Ethernet, gracefully degrades offline
- **Power Loss Recovery** ‚Äî Auto-save state, recover interrupted sessions
- **Model Configuration** ‚Äî Custom 1-4 model setups with performance analysis

### üõ°Ô∏è Resilience Features

- **Checkpoints** ‚Äî Save/restore code states (like Windsurf)
- **Autosave** ‚Äî State saved every 30 seconds while agents run
- **Graceful Degradation** ‚Äî Works offline (all models are local)
- **Recovery Alert** ‚Äî Offers to restore interrupted work on launch
- **Safe Operations** ‚Äî Confirmation before destructive actions

### ‚ö° Performance Optimized

| Layer | Optimization |
|-------|-------------|
| **File I/O** | Memory-mapped for files >64KB |
| **Caching** | LRU with `os_unfair_lock` |
| **Search** | Parallel trigram + word indexing |
| **Ollama** | Task-specific temperature/tokens |
| **Memory** | Auto-clear under pressure |
| **Models** | Pre-warmed on launch |

---

## üì¶ Installation

### üöÄ One-Line Setup (Recommended)

```bash
git clone https://github.com/cadenroberts/OllamaBot.git && cd OllamaBot && ./scripts/setup.sh
```

The setup script will:
- ‚úÖ Check system requirements (RAM, disk, macOS version)
- ‚úÖ Test network speed and optimize download parallelism  
- ‚úÖ Calculate disk space for your model selection
- ‚úÖ Install Ollama if needed
- ‚úÖ Download models in parallel (up to 4x faster)
- ‚úÖ Build the native macOS app
- ‚úÖ Install to /Applications

### Prerequisites

- **macOS 14.0** (Sonoma) or later
- **Apple Silicon** Mac (M1/M2/M3)
- **32GB RAM** recommended (16GB minimum)
- **20-80GB disk space** (depending on model selection)

### Manual Installation

<details>
<summary>Click to expand manual steps</summary>

#### Step 1: Install Ollama

```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

#### Step 2: Pull the Models

```bash
# Orchestrator (required)
ollama pull qwen3:32b

# Research Model
ollama pull command-r:35b

# Coding Model
ollama pull qwen2.5-coder:32b

# Vision Model (optional)
ollama pull qwen3-vl:32b
```

#### Step 3: Clone & Build

```bash
git clone https://github.com/cadenroberts/OllamaBot.git
cd OllamaBot

# Generate app icon (requires ImageMagick: brew install imagemagick)
./scripts/generate-icon.sh

# Build the app bundle
./scripts/build-app.sh --release
```

#### Step 4: Install & Run

```bash
# Install to Applications
cp -r build/OllamaBot.app /Applications/

# Or run directly
open build/OllamaBot.app
```

</details>

### Setup Script Options

```bash
./scripts/setup.sh              # Full interactive setup
./scripts/setup.sh --diagnose   # System diagnostics only
./scripts/setup.sh --space      # Disk space analysis only
./scripts/setup.sh --models     # Download models only
./scripts/setup.sh --build      # Build app only
```

### Development Mode

```bash
swift run OllamaBot   # Run from source
open Package.swift    # Open in Xcode
```

### obot CLI (Go)

The repository also includes `obot`, a standalone Go CLI for local AI code fixes and orchestration. For full documentation, see [README_CLI.md](README_CLI.md).

```bash
# Build & Install
make build && make install

# Usage
obot main.go                     # Fix entire file (default: balanced quality)
obot main.go -10 +25             # Fix lines 10-25
obot main.go "add error handling" --quality fast  # Fast fix with instruction
obot main.go -i                  # Interactive multi-turn mode

# Advanced Orchestration
obot orchestrate "Build an API"  # Full 5-schedule autonomous orchestration
obot plan src/                   # Generate an implementation plan
obot review main.go              # Expert code review (Expert Judge system)

# Session & Checkpoint Management
obot session list                # List USF (Unified Session Format) sessions
obot session show <id>           # Inspect detailed session history
obot session export <id>         # Export session for use in IDE
obot checkpoint save             # Save a snapshot of the current code state
obot checkpoint list             # List all available checkpoints

# Configuration & Stats
obot config migrate              # Migrate legacy JSON config to unified YAML
obot config unified              # View active unified configuration
obot stats --saved               # View accumulated cost savings vs GPT-4/Claude
```

Build requires Go 1.21+ and a running Ollama instance. The CLI auto-detects system RAM to select the optimal model.

#### Quality Presets
The CLI supports the same quality presets as the IDE via the `--quality` flag:
- `fast`: Single-pass execution, optimized for speed.
- `balanced`: Plan ‚Üí Execute ‚Üí Review loop (default).
- `thorough`: Plan ‚Üí Execute ‚Üí Review ‚Üí Revise loop with Expert Judge.

#### Unified Configuration

Both CLI and IDE read shared settings from `~/.config/ollamabot/config.yaml`:

```yaml
version: "2.0"
models:
  orchestrator: { default: "qwen3:32b" }
  coder:        { default: "qwen2.5-coder:32b" }
  researcher:   { default: "command-r:35b" }
  vision:       { default: "qwen3-vl:32b" }
quality:
  fast:     { iterations: 1, verification: "none" }
  balanced: { iterations: 2, verification: "llm_review" }
  thorough: { iterations: 3, verification: "expert_judge" }
context:
  max_tokens: 32768
  compression: { enabled: true, strategy: "semantic_truncate" }
orchestration:
  schedules: [knowledge, plan, implement, scale, production]
```

Migrate from the old JSON config with `obot config migrate`. A backward-compatible symlink from `~/.config/obot/` is created automatically.

---

## üéØ Usage

### Infinite Mode

1. Press `‚åò‚áßI` or click the **‚àû** button
2. Describe your task:
   - *"Add dark mode support to all views"*
   - *"Refactor this codebase to use async/await"*
   - *"Create unit tests for the user service"*
   - *"Document all public functions"*
3. Click **Start** and watch it work
4. **Stop** anytime to take control

### Chat Mode

Type in the chat panel on the right. The model auto-selects based on your question, or force a specific model:

| Shortcut | Model |
|----------|-------|
| `‚åò‚áß1` | Qwen3 (Writing) |
| `‚åò‚áß2` | Command-R (Research) |
| `‚åò‚áß3` | Qwen-Coder (Coding) |
| `‚åò‚áß4` | Qwen-VL (Vision) |
| `‚åò‚áß0` | Auto-route |

### Keyboard Shortcuts

| Shortcut | Action |
|----------|--------|
| `‚åòO` | Open folder |
| `‚åòN` | New file |
| `‚åòS` | Save file |
| `‚åòP` | Quick open |
| `‚åò‚áßP` | Command palette |
| `‚åòF` | Find in file |
| `‚åò‚áßF` | Search in files |
| `‚åò‚å•F` | Find and replace |
| `‚åÉG` | Go to line |
| `‚åòB` | Toggle sidebar |
| `‚åÉ\`` | Toggle terminal |
| `‚åò‚áßI` | Toggle Infinite Mode |

---

## üèóÔ∏è Architecture

### Project Structure

```
OllamaBot/
‚îú‚îÄ‚îÄ Sources/                             # Swift macOS IDE (73 files)
‚îÇ   ‚îú‚îÄ‚îÄ OllamaBotApp.swift               # App entry, state management
‚îÇ   ‚îú‚îÄ‚îÄ Agent/                           # 6 files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AgentExecutor.swift          # Infinite Mode engine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AgentTools.swift             # 18 tool definitions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AdvancedTools.swift          # Extended tool set (grep, glob, lint, etc.)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AdvancedToolExecutor.swift   # Executor for advanced tools
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CycleAgentManager.swift      # Explore Mode cycle manager
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ExploreAgentExecutor.swift   # Explore Mode engine
‚îÇ   ‚îú‚îÄ‚îÄ Models/                          # 3 files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatMessage.swift            # Chat data model (Codable)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FileItem.swift               # File tree model
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ OllamaModel.swift           # Model enum + metadata
‚îÇ   ‚îú‚îÄ‚îÄ Services/                        # 29 files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OllamaService.swift          # Ollama API client + streaming
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ContextManager.swift         # Context budget + compression
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IntentRouter.swift           # Model routing logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FileIndexer.swift            # Background search index
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FileSystemService.swift      # File operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ConfigurationService.swift   # Persistent settings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ InlineCompletionService.swift # Tab completions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ GitService.swift             # Git integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ WebSearchService.swift       # DuckDuckGo search
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatHistoryService.swift     # Persistent chat history
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CheckpointService.swift      # Save/restore code states
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ExternalLLMService.swift     # External LLM providers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ExternalModelConfigurationService.swift # Provider config
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ APIKeyStore.swift            # Secure API key storage
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MentionService.swift         # @mention resolution
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ModelTierManager.swift       # Model tier selection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ NetworkMonitorService.swift  # Connectivity detection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OBotService.swift            # .obotrules + .obot/ system
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ResilienceService.swift      # Power loss recovery
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SessionStateService.swift    # Session persistence
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SystemMonitorService.swift   # RAM/CPU monitoring
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PricingService.swift         # Cost tracking
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PerformanceTrackingService.swift # Perf metrics
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PanelConfiguration.swift     # Panel layout config
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SharedConfigService.swift    # CLI/IDE unified config
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OrchestrationService.swift   # 5-schedule orchestration state
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ToolRegistryService.swift    # Tool registry
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PreviewService.swift         # Dry-run diff preview
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ UnifiedSessionService.swift  # Cross-platform session format
‚îÇ   ‚îú‚îÄ‚îÄ Utilities/                       # 5 files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DesignSystem.swift           # UI components & tokens
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PerformanceCore.swift        # LRU cache, async I/O
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SyntaxHighlighter.swift      # Code highlighting
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DSScrollView.swift           # Custom scroll view
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Benchmarks.swift             # Performance testing
‚îÇ   ‚îî‚îÄ‚îÄ Views/                           # 29 files
‚îÇ       ‚îú‚îÄ‚îÄ MainView.swift               # Main layout + overlay dialogs
‚îÇ       ‚îú‚îÄ‚îÄ AgentView.swift              # Infinite Mode UI
‚îÇ       ‚îú‚îÄ‚îÄ ChatView.swift               # Chat panel
‚îÇ       ‚îú‚îÄ‚îÄ EditorView.swift             # Code editor
‚îÇ       ‚îú‚îÄ‚îÄ TerminalView.swift           # Terminal emulator
‚îÇ       ‚îú‚îÄ‚îÄ ExploreView.swift            # Explore Mode UI
‚îÇ       ‚îú‚îÄ‚îÄ ComposerView.swift           # Multi-file composer
‚îÇ       ‚îú‚îÄ‚îÄ CommandPaletteView.swift     # Command palette
‚îÇ       ‚îú‚îÄ‚îÄ OutlineView.swift            # Symbol navigation
‚îÇ       ‚îú‚îÄ‚îÄ ProblemsPanel.swift          # Errors/warnings
‚îÇ       ‚îú‚îÄ‚îÄ OrchestrationView.swift      # 5-schedule orchestration UI
‚îÇ       ‚îú‚îÄ‚îÄ CostDashboardView.swift      # Token usage & savings
‚îÇ       ‚îú‚îÄ‚îÄ SessionHandoffView.swift     # Cross-platform session export/import
‚îÇ       ‚îú‚îÄ‚îÄ PreviewView.swift            # Dry-run diff review
‚îÇ       ‚îú‚îÄ‚îÄ ConsultationView.swift       # Human consultation modal
‚îÇ       ‚îî‚îÄ‚îÄ ...                          # +14 more views
‚îÇ
‚îú‚îÄ‚îÄ cmd/obot/                            # Go CLI entry point
‚îÇ   ‚îî‚îÄ‚îÄ main.go
‚îú‚îÄ‚îÄ internal/                            # Go CLI packages (79 files, 28 packages)
‚îÇ   ‚îú‚îÄ‚îÄ cli/                             # Commands (fix, plan, review, orchestrate, stats, checkpoint, session, config)
‚îÇ   ‚îú‚îÄ‚îÄ ollama/                          # Ollama HTTP client + streaming
‚îÇ   ‚îú‚îÄ‚îÄ fixer/                           # Code fix engine + quality presets
‚îÇ   ‚îú‚îÄ‚îÄ orchestrate/                     # 5-schedule orchestration framework
‚îÇ   ‚îú‚îÄ‚îÄ agent/                           # Agent executor + delegation + action recording
‚îÇ   ‚îú‚îÄ‚îÄ analyzer/                        # File analysis + language detection
‚îÇ   ‚îú‚îÄ‚îÄ config/                          # Configuration loading/defaults + unified YAML migration
‚îÇ   ‚îú‚îÄ‚îÄ context/                         # Context budget, compression, memory, token management
‚îÇ   ‚îú‚îÄ‚îÄ router/                          # Intent-based model routing
‚îÇ   ‚îú‚îÄ‚îÄ session/                         # Session persistence + unified session format
‚îÇ   ‚îú‚îÄ‚îÄ tools/                           # Git, web, tool registry
‚îÇ   ‚îú‚îÄ‚îÄ tier/                            # System detection + model selection
‚îÇ   ‚îú‚îÄ‚îÄ ui/                              # Terminal UI + memory graph
‚îÇ   ‚îú‚îÄ‚îÄ stats/                           # Usage tracking + cost savings
‚îÇ   ‚îî‚îÄ‚îÄ ...                              # +14 more packages
‚îÇ
‚îú‚îÄ‚îÄ Installer/                           # macOS installer app
‚îÇ   ‚îú‚îÄ‚îÄ Package.swift
‚îÇ   ‚îî‚îÄ‚îÄ Sources/
‚îÇ
‚îú‚îÄ‚îÄ website/                             # Marketing site
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îî‚îÄ‚îÄ css/js/assets
‚îÇ
‚îú‚îÄ‚îÄ Resources/
‚îÇ   ‚îú‚îÄ‚îÄ Info.plist                       # App bundle metadata
‚îÇ   ‚îú‚îÄ‚îÄ AppIcon.icns                     # App icon
‚îÇ   ‚îî‚îÄ‚îÄ icon.svg                         # Source icon
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup.sh                         # Full interactive setup
‚îÇ   ‚îú‚îÄ‚îÄ build-app.sh                     # Build .app bundle
‚îÇ   ‚îú‚îÄ‚îÄ generate-icon.sh                 # Generate .icns from SVG
‚îÇ   ‚îú‚îÄ‚îÄ rebuild.sh                       # Fast rebuild
‚îÇ   ‚îî‚îÄ‚îÄ update.sh                        # Pull + rebuild + relaunch
‚îÇ
‚îú‚îÄ‚îÄ Package.swift                        # Swift Package Manager
‚îú‚îÄ‚îÄ go.mod                               # Go module definition
‚îú‚îÄ‚îÄ Makefile                             # Go CLI build system
‚îî‚îÄ‚îÄ README.md
```

### üß† Context Management System

OllamaBot's context management is the core differentiator from other AI IDEs. Here's how it works:

#### The Problem It Solves

AI models have limited context windows (8K-32K tokens). OllamaBot must intelligently:
1. **Prioritize** what context to include (selected code > open files > project structure)
2. **Compress** large contexts without losing critical information
3. **Pass context** between the orchestrator and specialist models
4. **Remember** past interactions and learn from errors

#### ContextManager Architecture

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ           ContextManager            ‚îÇ
                    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                    ‚îÇ  ‚Ä¢ Token Budget Allocation          ‚îÇ
                    ‚îÇ  ‚Ä¢ Semantic Compression             ‚îÇ
                    ‚îÇ  ‚Ä¢ Inter-Agent Context Passing      ‚îÇ
                    ‚îÇ  ‚Ä¢ Conversation Memory              ‚îÇ
                    ‚îÇ  ‚Ä¢ Error Pattern Learning           ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ                    ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   OrchestratorContext    ‚îÇ ‚îÇ    DelegationContext       ‚îÇ
        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
        ‚îÇ  ‚Ä¢ Task description      ‚îÇ ‚îÇ  ‚Ä¢ Optimized for specialist‚îÇ
        ‚îÇ  ‚Ä¢ Project structure     ‚îÇ ‚îÇ  ‚Ä¢ Relevant files included ‚îÇ
        ‚îÇ  ‚Ä¢ Recent steps summary  ‚îÇ ‚îÇ  ‚Ä¢ Context compressed      ‚îÇ
        ‚îÇ  ‚Ä¢ Relevant memories     ‚îÇ ‚îÇ  ‚Ä¢ Model-specific prompts  ‚îÇ
        ‚îÇ  ‚Ä¢ Error warnings        ‚îÇ ‚îÇ                            ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Token Budget Allocation

Each context section has a priority-based budget:

| Section | Priority | Max % of Budget |
|---------|----------|-----------------|
| **Task** | Critical | 25% |
| **File Content** | High | 33% |
| **Project** | High | 16% |
| **History** | Medium | 12% |
| **Memory** | Medium | 12% |
| **Errors** | High | 6% |

#### Inter-Agent Context Flow

```
User Task: "Fix the authentication bug"
                    ‚îÇ
                    ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   ORCHESTRATOR (Qwen3)        ‚îÇ
    ‚îÇ                               ‚îÇ
    ‚îÇ  ContextManager builds:       ‚îÇ
    ‚îÇ  ‚Ä¢ Full task + project map    ‚îÇ
    ‚îÇ  ‚Ä¢ Past relevant memories     ‚îÇ
    ‚îÇ  ‚Ä¢ Error warnings             ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚îÇ delegate_to_coder(task="Fix login validation")
                    ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   CODER (Qwen2.5-Coder)       ‚îÇ
    ‚îÇ                               ‚îÇ
    ‚îÇ  ContextManager builds:       ‚îÇ
    ‚îÇ  ‚Ä¢ Task (compressed)          ‚îÇ
    ‚îÇ  ‚Ä¢ Relevant files (extracted) ‚îÇ
    ‚îÇ  ‚Ä¢ Specialist system prompt   ‚îÇ
    ‚îÇ  ‚Ä¢ NO orchestrator bloat      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚îÇ Returns: Fixed code
                    ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   ORCHESTRATOR (Qwen3)        ‚îÇ
    ‚îÇ                               ‚îÇ
    ‚îÇ  Records:                     ‚îÇ
    ‚îÇ  ‚Ä¢ Tool result for reference  ‚îÇ
    ‚îÇ  ‚Ä¢ Memory entry for future    ‚îÇ
    ‚îÇ  ‚Ä¢ Verifies output validity   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Memory & Learning

The ContextManager maintains:

1. **Conversation Memory** - Past task/result pairs with relevance scoring
2. **Tool Results Buffer** - Recent 50 tool executions for reference
3. **Error Patterns** - Tracks recurring errors to warn the orchestrator

```swift
// Example: If "permissions" errors occur 2+ times, future tasks get warned:
"‚ö†Ô∏è WATCH OUT: Previously encountered issues with 'permissions'. Be careful."
```

### ‚ö° Streaming Performance

#### The Problem

Naive implementation updates `@Observable` state on every token (~60/sec):
```swift
// ‚ùå BAD: 60 state mutations/sec = 60 SwiftUI diffs/sec = choppy UI
for try await chunk in stream {
    chatMessages[index].content += chunk
}
```

#### The Solution: Frame-Coalesced Updates

```swift
// ‚úÖ GOOD: Batch updates to 30fps (every 33ms)
var buffer = ""
var lastUpdate = CACurrentMediaTime()

for try await chunk in stream {
    buffer.append(chunk)
    
    if CACurrentMediaTime() - lastUpdate >= 0.033 {  // 30fps
        chatMessages[index].content = buffer  // Single diff
        lastUpdate = CACurrentMediaTime()
    }
}
```

#### Additional Optimizations

| Component | Optimization |
|-----------|-------------|
| **MessageRow** | `Equatable` conformance - only re-renders when content changes |
| **AssistantContentView** | Cached markdown parsing - reparse only on content change |
| **OllamaService** | Buffer tokens to ~50 chars before yielding |
| **Throttler** | Rate-limits scroll, resize, search events |
| **Debouncer** | Delays expensive operations (search, highlight) |

### üîÑ Model Routing (IntentRouter)

The IntentRouter automatically selects the best model based on the user's question:

```swift
// Keyword-based classification
"How do I implement async/await?" ‚Üí Coder (detected: "implement", "async", "await")
"What is quantum computing?"     ‚Üí Researcher (detected: "what is")
"Write me a haiku about coding"  ‚Üí Writing (detected: "write")
[Image attached]                 ‚Üí Vision (automatic)
```

Priority order:
1. **Vision** - If images attached
2. **Coder** - Code keywords + code context open
3. **Researcher** - Question words, "explain", "compare"
4. **Writing** - Default for general tasks

### üõ†Ô∏è Tool Execution Pipeline

Agent tools execute in parallel when possible:

```
Tool Calls: [read_file(A), read_file(B), search_files(C)]
                           ‚îÇ
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚ñº               ‚ñº               ‚ñº
    [Read File A]   [Read File B]   [Search Files]
           ‚îÇ               ‚îÇ               ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚ñº
              [Results aggregated & returned]
```

Non-parallelizable tools (write_file, run_command) execute sequentially.

---

## ‚öôÔ∏è Configuration

Access settings via `‚åò,` or the menu bar.

### Editor
- Font family & size
- Tab size & spaces
- Word wrap
- Line numbers
- Minimap
- Auto-close brackets
- Format on save

### AI
- Default model
- Temperature (0.0 - 1.0)
- Max tokens
- Context window size
- Include file context
- Stream responses

### Agent (Infinite Mode)
- Max steps limit
- Allow terminal commands
- Allow file writes
- Confirm destructive actions

### Appearance
- Theme (System/Light/Dark)
- Sidebar width
- Status bar visibility
- Breadcrumbs

---

## üé® Design System

OllamaBot uses a **Tokyo Night**-inspired color palette with a **blue-only** unified theme:

```swift
// Core Colors
background:     #1a1b26  // Deep background
surface:        #1f2335  // Cards, panels
accent:         #7dcfff  // Brand cyan-blue
accentAlt:      #2ac3de  // Teal-blue

// Model Colors (Blue Spectrum)
orchestrator:   #7aa2f7  // Royal blue (Qwen3)
researcher:     #2ac3de  // Teal blue (Command-R)
coder:          #7dcfff  // Cyan blue (Qwen-Coder)
vision:         #5a8fd4  // Steel blue (Qwen-VL)

// Semantic (Blue variants)
success:        #73c0ff  // Light blue
info:           #7aa2f7  // Info blue
```

---

## üîß Troubleshooting

### "Ollama Disconnected"
```bash
ollama serve
```

### Slow Model Switching
Normal ‚Äî 32B models take ~30s to load. The orchestrator stays warm.

### High Memory Usage
Use **Debug ‚Üí Clear Caches** or restart the app.

### Agent Seems Stuck
Check the step list ‚Äî it may be thinking or waiting. Stop and retry with a more specific task.

---

## üìä Performance

Run benchmarks: **Debug ‚Üí Run Performance Benchmarks**

Typical results on M1 Max 32GB:

| Metric | Value |
|--------|-------|
| Cache ops | ~400,000/sec |
| File reads (small) | ~35,000/sec |
| File reads (1MB) | ~20/sec (mmap) |
| Parallel speedup | 3.5x |
| First AI response | ~instant (warmed) |

---

## ü§ù Contributing

Contributions welcome! This is an experiment in local AI autonomy.

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run `swift build` to verify
5. Submit a pull request

---

## üìÑ License

MIT License ‚Äî see [LICENSE](LICENSE) for details.

---

## üôè Acknowledgments

- [Ollama](https://ollama.ai) for making local LLMs accessible
- [SwiftTerm](https://github.com/migueldeicaza/SwiftTerm) for terminal emulation
- [Tokyo Night](https://github.com/enkia/tokyo-night-vscode-theme) for color inspiration

---

<div align="center">

**Built with ‚ù§Ô∏è for local AI enthusiasts**

*Your AI should work FOR you, not wait ON you.*

</div>
